Terraform

resource cheat list

> terraform
usage: terraform [--version] [--help] <command> [<args>]
Available commands are:
 apply Builds or changes infrastructure
 destroy Destroy Terraform-managed infrastructure
 get Download and install modules for the configuration
 graph Create a visual graph of Terraform resources
 (...)


You can even get Terraform to show you the dependency graph by running the
graph command
digraph {
 compound = "true"
 newrank = "true"
 subgraph "root" {
 "[root] aws_instance.example"
 [label = "aws_instance.example", shape = "box"]
 "[root] aws_security_group.instance"
 [label = "aws_security_group.instance", shape = "box"]
 "[root] provider.aws"
 [label = "provider.aws", shape = "diamond"]
 "[root] aws_instance.example" -> "[root] aws_security_group.instance"
 "[root] aws_instance.example" -> "[root] provider.aws"
 "[root] aws_security_group.instance" -> "[root] provider.aws"
 }
}


###Provider "aws"
Syntax
provider "aws" {}


Method1:
provider "aws" {
  access_key = "${var.aws_access_key}"
  secret_key = "${var.aws_secret_key}"
  region     = "us-east-1"
}

Regarding the credentials : - It can be provided as the env variable, or variables

Method2:
Providing the creds as env variables
$ export AWS_ACCESS_KEY_ID="anaccesskey"
$ export AWS_SECRET_ACCESS_KEY="asecretkey"
$ export AWS_DEFAULT_REGION="us-west-2

provider "aws" {
  region     = "us-west-2"
  access_key = "AWS_ACCESS_KEY_ID"
  secret_key = "AWS_SECRET_ACCESS_KEY"
}


Method3:
provider "aws" {
  region                  = "us-west-2"
  shared_credentials_file = "/Users/tf_user/.aws/creds"
  profile                 = "customprofile"
}





##############Resources
#Create elb
resource "aws_elb" "example" {
 name = "terraform-asg-example"
 availability_zones = ["us-west-2a", "us-west-2b", "us-west-2c"]
}

access_logs {
    bucket        = "foo"
    bucket_prefix = "bar"
    interval      = 60
  }

  listener {
    instance_port     = 8000
    instance_protocol = "http"
    lb_port           = 80
    lb_protocol       = "http"
  }

listener {
    instance_port      = 8000
    instance_protocol  = "http"
    lb_port            = 443
    lb_protocol        = "https"
    ssl_certificate_id = "arn:aws:iam::123456789012:server-certificate/certName"
  }

  health_check {
    healthy_threshold   = 2
    unhealthy_threshold = 2
    timeout             = 3
    target              = "HTTP:8000/"
    interval            = 30
  }

  instances                   = ["${aws_instance.foo.id}"]
  cross_zone_load_balancing   = true
  idle_timeout                = 400
  connection_draining         = true
  connection_draining_timeout = 400

  tags = {
    Name = "foobar-terraform-elb"
  }
}



#Spinning ec2 instance with  user data
##aws_instance
resource "aws_instance" "app" {
 instance_type = "t2.micro"
 availability_zone = "us-east-1a"
 ami = "ami-40d28157"

 user_data = <<-EOF
 #!/bin/bash
 sudo service apache2 start
 EOF
}

Notes:
A resource block declares a resource of a given type ("aws_instance") with a given local name ("web"). The name is used to refer to this resource from elsewhere in the same Terraform module

##aws_instance with ebs block storage
resource "aws_instance" "example" {
  ami           = "ami-2757f631"
  instance_type = "t2.micro"
}

resource "aws_ebs_volume" "example-volume" {
  availability_zone = "${aws_instance.example.availability_zone}"
  type              = "gp2"
  size              = 100
}
 
resource "aws_volume_attachment" "ebs_att" {
  device_name = "/dev/sdh"
  volume_id   = "${aws_ebs_volume.example.id}"
  instance_id = "${aws_instance.example.id}"
}




#Spinning 10 instances
resource "aws_instance" "example" {
 count = 10
 ami = "ami-40d28157"
 instance_type = "t2.micro"
}

#security group
resource "aws_security_group" "elb" {
 name = "${var.cluster_name}-elb"
 
 ingress {
 from_port = 80
 to_port = 80
 protocol = "tcp"
 cidr_blocks = ["0.0.0.0/0"]
 }
 
 egress {
 from_port = 0
 to_port = 0
 protocol = "-1"
 cidr_blocks = ["0.0.0.0/0"]
 }
}


#creating inbound and outbound security group
resource "aws_security_group" "allow_ssh" {
  name        = "allow-ssh"
  description = "Allow SSH inbound traffic"

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

resource "aws_security_group" "allow_outbound" {
  name        = "allow-all-outbound"
  description = "Allow all outbound traffic"

  egress {
    from_port = 0
    to_port = 0
    protocol = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

#Instance creation
resource "aws_instance" "my-test-instance" {
  ami             = "${data.aws_ami.ubuntu.id}"
  instance_type   = "t2.micro"

  security_groups = [
    "${aws_security_group.allow_ssh.name}", ----------------------metioning the security group
    "${aws_security_group.allow_outbound.name}"
  ]

  tags {
    Name = "test-instance"
  }
}

#Notes:
This will attach the security groups we just created, to our EC2  instance. Allowing it to receive incoming connections on port 22 and  allowing all outbound connections from the server


#creating a key pair in terraform

step1:
$ cd ~/.ssh/
$ ssh-keygen -t rsa -b 2048 -v

Step2:
 cat ~/.ssh/my_test_key.pub > my_test_key.pub

step3:
resource "aws_key_pair" "my-test-key" {
  key_name   = "test-key"
  public_key = "${file("my_test_key.pub")}"
}

step4:
resource "aws_instance" "my-test-instance" {
  ami             = "${data.aws_ami.ubuntu.id}"
  instance_type   = "t2.micro"
  key_name        = "${aws_key_pair.my-test-key.key_name}"

  security_groups = [
    "${aws_security_group.allow_ssh.name}",
    "${aws_security_group.allow_outbound.name}"
  ]

  tags {
    Name = "test-instance"
  }
}




#Create s3 bucket
resource "aws_s3_bucket" "terraform_state" {
 bucket = "terraform-up-and-running-state"
 versioning {
 enabled = true
 }
 lifecycle {
 prevent_destroy = true
 }
}

#Autoscaling in ec2 using recorrance
resource "aws_autoscaling_schedule" "scale_out_during_business_hours" {
 scheduled_action_name = "scale-out-during-business-hours"
 min_size = 2
 max_size = 10
 desired_capacity = 10
 recurrence = "0 9 * * *"
}

Notes::means scale your ec2 every day by 10 AM

#Scale the instances aft 5pm
resource "aws_autoscaling_schedule" "scale_in_at_night" {
 scheduled_action_name = "scale-in-at-night"
 min_size = 2
 max_size = 10
 desired_capacity = 2
 recurrence = "0 17 * * *"
}


#Create users based on the names
resource "aws_iam_user" "example" {
 count = 3
 name = "neo.${count.index}"
}

#resource "aws_iam_policy" "ec2_read_only" {
 name = "ec2-read-only"
 policy = "${data.aws_iam_policy_document.ec2_read_only.json}"
}

where policy json has be metnioned in the same file



#ouput the data to console
output "public_ip" {
 value = "${aws_instance.example.public_ip}"
}


#VPC creation
resource "aws_vpc" "test-env" {
  cidr_block = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support = true
  tags {
    Name = "test-env"
  }
}

Notes:
Here we are asking Terraform to set up an AWS VPC resource named â€œtest-envâ€. The CIDR BLOCK is used to configure the expanse of our network. Higher the value that comes after â€œ/â€ the smaller our network will be. A tag called â€œNameâ€ was added to let us easily identify the VPC


Setting up the inputs:
//variables.tf
variable "ami_name" {}
variable "ami_id" {}
variable "ami_key_pair_name" {}

example
variable "aws_access_key" {
  default = "YOUR_ADMIN_ACCESS_KEY}

variable "aws_secret_key" {
  default = "YOUR_ADMIN_SECRET_KEY"
}

variable "aws_region" {
  default = "us-west-2"
}

Notes: To use variables inside the terraform
To use an input variable in your resources, you need to use Terraform’s interpolation
syntax:
"${something_to_interpolate}"

Another way of mentioning the variables
variables
a.
variable "server_port" {
description = "The port the server will use for HTTP requests"
default = 8080
}

b. command line variables
terraform plan -var server_port="8080" mentioning the varibale during the execution




b. Subnet creations
resource "aws_subnet" "subnet-uno" {
  cidr_block = "${cidrsubnet(aws_vpc.test-env.cidr_block, 3, 1)}"
  vpc_id = "${aws_vpc.test-env.id}"
  availability_zone = "us-east-1a"
}




#Using provisiors in ansible
provisioner "remote-exec" {
    inline = [
      "command curl -sSL https://rvm.io/mpapis.asc | gpg --import -",
      "\\curl -sSL https://get.rvm.io | bash -s stable --rails",
    ]


#Using the provisioner local-exec
provisioner "local-exec" {
    command = "echo ${aws_instance.web.private_ip} >> private_ips.txt"
  }
}
Notes:
The local-exec provisioner invokes a local executable after a resource is created. This invokes a process on the machine running Terraform, not on the resource

#Using file provsioner
provisioner "file" {
    source      = "conf/myapp.conf"
    destination = "/etc/myapp.conf"
  }

provisioner "file" {
    content     = "ami used: ${self.ami}"
    destination = "/tmp/file.log"
  }


 # Copies the configs.d folder to /etc/configs.d
  provisioner "file" {
    source      = "conf/configs.d"
    destination = "/etc"
  }
  
Note:
The file provisioner is used to copy files or directories from the machine executing Terraform to the newly created resource.



#Multiple Provisioners
Multiple provisioners can be specified within a resource. Multiple provisioners are executed in the order they're defined in the configuration file.

 provisioner "local-exec" {
    command = "echo first"
  }
  provisioner "local-exec" {
    command = "echo second"
  }
}


#




#Failure Behaviour
using "on_failure" 
By default, provisioners that fail will also cause the Terraform apply itself to error
on_failure setting can be used to change this
Allow values
"continue" - Ignore the error and continue with creation or destruction.
"fail" - Error (the default behavior). If this is a creation provisioner, taint the resource.
resource "aws_instance" "web" {
  # ...

  provisioner "local-exec" {
    command    = "echo ${self.private_ip} > file.txt"
    on_failure = "continue"
  }
}





-----------------------------------------------------------------------------------------------


Terraform phases
1.terraform init

This will download and install the proper version of the AWS provider for your project and place it in a directory called .terraform.
You should see a message like this in response:

Initializing provider plugins...
- Checking for available provider plugins on https://releases.hashicorp.com...
- Downloading plugin for provider "aws" (1.7.0)...

Terraform has been successfully initialized!


2. Terraform plan
To see any changes that are required for your infrastructure. All Terraform commands
should now work.
If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
We'll now run the command that will take the configurations we've  written and use the 

The plan command lets you see what Terraform will do before actually making any
changes.
This is a great way to sanity check your code before unleashing it onto the
world.
resources with a plus sign (+) are going to
be created, resources with a minus sign (-) are going to be deleted, and resources with
a tilde sign (~) are going to be modified

output
[root@centos7-jen terraform]# terraform plan
Refreshing Terraform state in-memory prior to plan...
The refreshed state will be used to calculate this plan, but will not be
persisted to local or remote state storage.


------------------------------------------------------------------------

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  + aws_instance.app
      id:                           <computed>
      ami:                          "ami-40d28157"
      arn:                          <computed>
      associate_public_ip_address:  <computed>
      availability_zone:            "us-east-1a"
      cpu_core_count:               <computed>
      cpu_threads_per_core:         <computed>
      ebs_block_device.#:           <computed>
      ephemeral_block_device.#:     <computed>
      get_password_data:            "false"
      host_id:                      <computed>
      instance_state:               <computed>
      instance_type:                "t2.micro"
      ipv6_address_count:           <computed>
      ipv6_addresses.#:             <computed>
      key_name:                     <computed>
      network_interface.#:          <computed>
      network_interface_id:         <computed>
      password_data:                <computed>
      placement_group:              <computed>
      primary_network_interface_id: <computed>
      private_dns:                  <computed>
      private_ip:                   <computed>
      public_dns:                   <computed>
      public_ip:                    <computed>
      root_block_device.#:          <computed>
      security_groups.#:            <computed>
      source_dest_check:            "true"
      subnet_id:                    <computed>
      tenancy:                      <computed>
      user_data:                    "5f0133e03a8ff26e8a04dc6131faca65099769a3"
      volume_tags.%:                <computed>
      vpc_security_group_ids.#:     <computed>


Plan: 1 to add, 0 to change, 0 to destroy.

------------------------------------------------------------------------

Note: You didn't specify an "-out" parameter to save this plan, so Terraform
can't guarantee that exactly these actions will be performed if
"terraform apply" is subsequently run.








3.
terraform apply
Terraform analyzes the existing resources in your AWS account and  builds a plan of exactly what it will do and why. It outputs this plan  and asks whether or not you'd like to make the changes

4.terraform destroy
terraform destroy
This will destroy the infra created.


#Create a Loadbalancer
-----------------------
resource "aws_elb" "example" {
name = "terraform-asg-example"
availability_zones = ["${data.aws_availability_zones.all.names}"]


listener {
lb_port = 80
lb_protocol = "http"
instance_port = "${var.server_port}"
instance_protocol = "http"
}
}


------------------------------------------------------------------------------------------------------------------------------
###data sources
##To get the latest AMI without manually hard coding the the value

data "aws_ami" "example" {
  most_recent = true

  owners = ["self"]
  tags = {
    Name   = "app-server"
    Tested = "true"
  }
}



Errors

a.Error: Error running plan: 1 error(s) occurred:

* provider.aws: error validating provider credentials: error calling sts:GetCallerIdentity: SignatureDoesNotMatch: Signature expired: 20190508T154320Z is now earlier than 20190509T073124Z (20190509T074624Z - 15 min.)
        status code: 403, request id: 8bb46cc2-722e-11e9-905b-a3bb4bf74c80

Solution
start the chrony service.

b.* provider.aws: error validating provider credentials: error calling sts:GetCallerIdentity: SignatureDoesNotMatch: Signature expired: 20190509T131339Z is now earlier than 20190509T135301Z (20190509T140801Z - 15 min.)
        status code: 403, request id: db51557d-7263-11e9-9a77-d5914a2f1

solution
root@centos7-jen terraform]# ntpdate pool.ntp.org
 9 May 19:39:24 ntpdate[29017]: step time server 123.108.200.124 offset 3254.804513 sec





Terraform notes
https://medium.com/@hmalgewatta/setting-up-an-aws-ec2-instance-with-ssh-access-using-terraform-c336c812322f
https://letslearndevops.com/2017/07/24/how-to-create-a-vpc-with-terraform/
